{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.metrics import confusion_matrix, classification_report # analyzing model's performance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating File DataFrame","metadata":{}},{"cell_type":"code","source":"# copy path from images folder on right bar\n# convert directory to Path object\nimage_dir = Path(\"/kaggle/input/\")\n\nfilepaths = list(image_dir.glob(r'**/*.jpg')) # Path object has \"glob\" function that lets us target files in directory (**/*.jpg is an expression to search anything that ends with jpg in directory)\nos.path.split(filepaths[0]) # split path object so we get prefix and file\nos.path.split(os.path.split(filepaths[0])[0])[1] # get class name only (which is in the file name)\n\n# map each jpg into class name\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\n# convert into pandas series and concat into dataframe\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str) # IMAGES (convert path obj to string)\nlabels = pd.Series(labels, name='Label')                      # LABELS (already a string)\n\nimages = pd.concat([filepaths, labels], axis=1) # axis=1 means side by side\nimages","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are 1000 images for 101 foods, which takes forever to train. \n# Instead, we will only take 100 images from 101 foods for sake of speed.\n\n# axis=0 means concat on top of each other\n# frac=1 means simple shuffling without removing anything\n# random_state=1 means making the random shuffle reproducible\n# reset_index because indices were also shuffled\n# drop=True to prevent old indices from becoming new column\ncategory_samples = []\nfor category in images['Label'].unique():\n    category_slice = images.query(\"Label == @category\") # for every @category / \"label\"\n    category_samples.append(category_slice.sample(100, random_state=1)) # randomly sample 100\nimage_df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True) \n\nimage_df['Label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-Test Split","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Generators\n\nGenerators are a nice way to load images one batch at a time so we don't run out of memory. We set batch size to 32, load 32 images, train on images, recycle memory for the next batch size so we don't run out of memory.","metadata":{}},{"cell_type":"code","source":"# preprocessing function preprocesses a tensor or Numpy array encoding a batch of images. The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling.\ntrain_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n    validation_split=0.2\n    # data augmentation\n    rotation_range=5, \n#     width_shift_range=0.1, \n#     height_shift_range=0.1, \n#     zoom_range=0.1,\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.resnet50.preprocess_input\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flow_from_dataframe = df specifies which images we're using, generator takes images from dataframe, trains on them, and recycles them\n# color_mode=rgb = we're using rgb images\n# class_mode=categorical = multiclass classification task\n# shuffle=True = shuffle after each epoch during training\n# seed=42 = so we can reproduce results\n# subset=training = only available if we're using a validation split, and it specfifies if we're using the 80% training or 80% validation\n# train_images holds specifications on how to pull files. This later goes into fit function\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col=\"Filepath\",\n    y_col=\"Label\",\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    target_size=(224, 224),\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset=\"training\"\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col=\"Filepath\",\n    y_col=\"Label\",\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    target_size=(224, 224),\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset=\"validation\"\n)\n\n# no shuffling, no seed, no subset\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col=\"Filepath\",\n    y_col=\"Label\",\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    target_size=(224, 224),\n    batch_size=32,\n    shuffle=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"# input_shape differs for each model (3 is for RGB)\n# include_top = do we want to keep final classification layer that the original model was trained on (i.e imagenet has 1000 classes, but we want to put our own food classification layer)\n# avg pooling = output of pre-trained model is 1D (average across all but 1D so we get 1D output)\npretrained_model = tf.keras.applications.ResNet50(\n    input_shape=(150,150,3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\n# IMPORTANT: does not mess with original imagenet weights\n# using a pre-trained model = transfer learning\n# pre-trained model is built to be very good at extracting useful features from images (known as feature exrtactor)\n# the convolutional layer that isn't the top (i.e classification) is meant to extract features (2D features like shapes) from images\npretrained_model.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input layer\ninputs = pretrained_model.input\n\n# 2 dense layers\nx = tf.keras.layers.Dense(120, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(120, activation='relu')(x)\n\n# classification layer\noutputs = tf.keras.layers.Dense(101, activation=\"softmax\")(x) # 101 classes, probabilities of all 101 classes sum to 1\n\nmodel = tf.keras.Model(inputs, outputs)\n\n# only the last 3 layers are trainable params (avg_pool, dense_1, dense_2)\n# print(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training\n\nturn on GPU acceleration on Kaggle for faster training","metadata":{}},{"cell_type":"code","source":"# reason we don't use sparse_catergorical_entropy is because when we use image data generators it encodes classes as vectors. Instead of passing in integers for each class, we get one-hot vector for the class. When you pass it in vector form use categorical_crossentropy, when passing it in integer form use sparse_categorical_entropy\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\n# earlystopping callback function to stop when validation loss stops improving\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=30,\n#     callbacks=[\n#         tf.keras.callbacks.EarlyStopping(\n#             # when validation loss stops improving for 3 consecutive epochs, restore weights from the best epoch\n#             monitor=\"val_loss\",\n#             patience=3,\n#             restore_best_weights=True\n#         )\n#     ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_images)\nprint(\"Test accuracy: {:.2f}%\".format(results[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get index of highest probability value (axis 1 to get highest probability for each test image)\npredictions = np.argmax(model.predict(test_images), axis=1)\n\n# from sklearn - actual labels vs predicted labels\ncm = confusion_matrix(test_images.labels, predictions)\n\n# from sklearn - list of how well each class was predicted\nclr = classification_report(test_images.labels, predictions, target_names=test_images.class_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\n# fmt='g' so we see integers and not scientific notation\n# cbar=false turn off color bar\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap=\"Blues\", cbar=False)\n# spacing of ticks is np.arrange / evenly among 101 classes\n# test_images.class_indices is a mapping of class to index (uses this dictionary for labels)\nplt.xticks(ticks=np.arange(101) + 0.5, labels=test_images.class_indices, rotation=90)\nplt.yticks(ticks=np.arange(101) + 0.5, labels=test_images.class_indices, rotation=0)\nplt.xlabel=(\"Predicted\")\nplt.ylabel=(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Classification Report:\\n-----------------------\\n\", clr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}